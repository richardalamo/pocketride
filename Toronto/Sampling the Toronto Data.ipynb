{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67f38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import folium\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from folium.plugins import HeatMap\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from folium.plugins import MarkerCluster\n",
    "from IPython.display import display\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106daa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Toronto Bikeshare May2023 - Apr2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9293647",
   "metadata": {},
   "source": [
    "# Rationale for Stratified Sampling in Bikeshare Data Analysis\n",
    "\n",
    "## Introduction\n",
    "The Toronto Bikeshare dataset (May 2023 - April 2024) contains over 5.3 million records, which can be computationally intensive for analysis. Implementing a stratified sampling approach allows us to work with a more manageable dataset while maintaining the essential characteristics of the original data.\n",
    "\n",
    "## Why Stratified Sampling?\n",
    "\n",
    "### 1. Seasonal Variation\n",
    "- Bikeshare usage varies significantly by month\n",
    "- Summer months (June-September) show higher usage\n",
    "- Winter months (December-February) show lower usage\n",
    "- Stratification by month ensures representation of all seasonal patterns\n",
    "\n",
    "### 2. Data Volume\n",
    "- Original dataset: 5,336,042 records\n",
    "- Storage and processing challenges with full dataset\n",
    "- Need for efficient analysis while maintaining data integrity\n",
    "- 10% sample reduces data to ~533,604 records\n",
    "\n",
    "### 3. Monthly Distribution in Original Data\n",
    "```\n",
    "2023-05: 512,228 records\n",
    "2023-06: 584,517 records\n",
    "2023-07: 650,399 records\n",
    "2023-08: 676,439 records\n",
    "2023-09: 673,179 records\n",
    "2023-10: 544,630 records\n",
    "2023-11: 361,306 records\n",
    "2023-12: 237,125 records\n",
    "2024-01: 189,684 records\n",
    "2024-02: 242,123 records\n",
    "2024-03: 289,239 records\n",
    "2024-04: 375,173 records\n",
    "```\n",
    "\n",
    "## Sampling Methodology\n",
    "\n",
    "### 1. Proportional Stratification\n",
    "- Each month sampled independently\n",
    "- Sampling fraction: 10% of each month's records\n",
    "- Maintains original monthly distribution patterns\n",
    "\n",
    "### 2. Random Selection\n",
    "- Random seed set for reproducibility\n",
    "- Within each month stratum, random selection of records\n",
    "- Prevents selection bias within months\n",
    "\n",
    "### 3. Benefits of This Approach\n",
    "- Preserves seasonal patterns\n",
    "- Maintains proportional representation of each month\n",
    "- Reduces computational requirements\n",
    "- Enables more efficient analysis\n",
    "- Ensures representation of low-usage periods\n",
    "\n",
    "## Implementation Considerations\n",
    "\n",
    "### 1. Sample Size Determination\n",
    "- 10% chosen as it provides:\n",
    "  * Sufficient data for statistical analysis\n",
    "  * Manageable dataset size\n",
    "  * Adequate representation of rare events\n",
    "  * Balance between precision and efficiency\n",
    "\n",
    "### 2. Stratification Variable\n",
    "- Month chosen as primary stratification variable because:\n",
    "  * Strong seasonal patterns in bikeshare usage\n",
    "  * Different user behaviors across seasons\n",
    "  * Varying weather conditions impact usage\n",
    "  * Monthly operational patterns\n",
    "\n",
    "### 3. Random Seed\n",
    "- Fixed random seed (42) used for:\n",
    "  * Reproducibility of results\n",
    "  * Consistency in repeated analyses\n",
    "  * Ability to verify findings\n",
    "\n",
    "## Expected Outcomes\n",
    "- Reduced dataset size while maintaining:\n",
    "  * Seasonal patterns\n",
    "  * Usage distributions\n",
    "  * Key relationships between variables\n",
    "  * Representative sample of user behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31ca3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Records:\n",
      "Original: 5,336,042\n",
      "Sampled: 533,604\n",
      "Overall sampling ratio: 10.0%\n",
      "\n",
      "Monthly Breakdown:\n",
      "------------------------------------------------------------\n",
      "Month-Year | Original Count | Sampled Count | Sampling Ratio\n",
      "------------------------------------------------------------\n",
      "2023-05   |       512,228 |       51,223 |          10.0%\n",
      "2023-06   |       584,517 |       58,452 |          10.0%\n",
      "2023-07   |       650,399 |       65,040 |          10.0%\n",
      "2023-08   |       676,439 |       67,644 |          10.0%\n",
      "2023-09   |       673,179 |       67,318 |          10.0%\n",
      "2023-10   |       544,630 |       54,463 |          10.0%\n",
      "2023-11   |       361,306 |       36,131 |          10.0%\n",
      "2023-12   |       237,125 |       23,712 |          10.0%\n",
      "2024-01   |       189,684 |       18,968 |          10.0%\n",
      "2024-02   |       242,123 |       24,212 |          10.0%\n",
      "2024-03   |       289,239 |       28,924 |          10.0%\n",
      "2024-04   |       375,173 |       37,517 |          10.0%\n"
     ]
    }
   ],
   "source": [
    "def simple_stratified_sample(df, sample_fraction=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Simplified version of stratified sampling that takes 10% of each month's data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing bikeshare data\n",
    "    sample_fraction : float, default=0.1\n",
    "        Fraction of data to sample from each month\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Sampled dataframe\n",
    "    dict\n",
    "        Basic sampling statistics\n",
    "    \"\"\"\n",
    "    # Ensure Date is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Create Month-Year column\n",
    "    df['Month-Year'] = df['Date'].dt.to_period('M')\n",
    "    \n",
    "    # Calculate sample sizes\n",
    "    monthly_counts = df['Month-Year'].value_counts()\n",
    "    monthly_sample_sizes = (monthly_counts * sample_fraction).round().astype(int)\n",
    "    \n",
    "    # Initialize statistics dictionary\n",
    "    stats = {\n",
    "        'original_total': len(df),\n",
    "        'monthly_stats': {}\n",
    "    }\n",
    "    \n",
    "    # Perform sampling\n",
    "    sampled_df = pd.DataFrame()\n",
    "    \n",
    "    for month, sample_size in monthly_sample_sizes.items():\n",
    "        # Get month's data\n",
    "        monthly_data = df[df['Month-Year'] == month]\n",
    "        \n",
    "        # Sample from this month\n",
    "        month_sample = monthly_data.sample(n=sample_size, random_state=random_state)\n",
    "        \n",
    "        # Add to sampled dataframe\n",
    "        sampled_df = pd.concat([sampled_df, month_sample])\n",
    "        \n",
    "        # Store statistics\n",
    "        stats['monthly_stats'][str(month)] = {\n",
    "            'original_count': len(monthly_data),\n",
    "            'sampled_count': sample_size,\n",
    "            'sampling_ratio': (sample_size / len(monthly_data)) * 100\n",
    "        }\n",
    "    \n",
    "    # Reset index\n",
    "    sampled_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add final statistics\n",
    "    stats['sampled_total'] = len(sampled_df)\n",
    "    stats['overall_sampling_ratio'] = (len(sampled_df) / len(df)) * 100\n",
    "    \n",
    "    return sampled_df, stats\n",
    "\n",
    "def print_simple_summary(stats):\n",
    "    \"\"\"\n",
    "    Print a simple summary of the sampling results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nTotal Records:\")\n",
    "    print(f\"Original: {stats['original_total']:,}\")\n",
    "    print(f\"Sampled: {stats['sampled_total']:,}\")\n",
    "    print(f\"Overall sampling ratio: {stats['overall_sampling_ratio']:.1f}%\")\n",
    "    \n",
    "    print(\"\\nMonthly Breakdown:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Month-Year | Original Count | Sampled Count | Sampling Ratio\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for month, data in sorted(stats['monthly_stats'].items()):\n",
    "        print(f\"{month:9} | {data['original_count']:13,d} | \"\n",
    "              f\"{data['sampled_count']:12,d} | {data['sampling_ratio']:13.1f}%\")\n",
    "\n",
    "\n",
    "sampled_df, stats = simple_stratified_sample(df)\n",
    "print_simple_summary(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273ac01",
   "metadata": {},
   "source": [
    "# Rationale for Comparing Original and Sampled Datasets\n",
    "\n",
    "## Introduction\n",
    "After creating a stratified sample, it's crucial to validate that the sample accurately represents the original dataset. This comparison ensures that any analyses performed on the sample will yield reliable insights applicable to the full dataset.\n",
    "\n",
    "## Why Compare Datasets?\n",
    "\n",
    "### 1. Validation of Sampling Method\n",
    "- Verify that stratified sampling maintained data characteristics\n",
    "- Ensure no systematic bias was introduced\n",
    "- Confirm representation of key patterns and relationships\n",
    "\n",
    "### 2. Statistical Integrity\n",
    "- Verify distribution shapes\n",
    "- Confirm maintenance of central tendencies\n",
    "- Validate spread and variability measures\n",
    "\n",
    "### 3. Quality Assurance\n",
    "- Detect any potential sampling errors\n",
    "- Identify any lost information\n",
    "- Ensure reliability for further analysis\n",
    "\n",
    "## Comparison Methodology\n",
    "\n",
    "### 1. Descriptive Statistics\n",
    "- Compare basic statistics between datasets:\n",
    "  * Mean, median, standard deviation\n",
    "  * Minimum and maximum values\n",
    "  * Quartile values\n",
    "  * Distribution shapes\n",
    "\n",
    "### 2. Statistical Tests\n",
    "- Kolmogorov-Smirnov (KS) test\n",
    "  * Tests if samples come from same distribution\n",
    "  * p-value > 0.05 indicates similar distributions\n",
    "- Chi-square test for categorical variables\n",
    "  * Tests if categorical distributions match\n",
    "  * Validates user type and temporal patterns\n",
    "\n",
    "### 3. Outlier Analysis\n",
    "- Z-score method (|z| > 3)\n",
    "  * Identifies extreme values\n",
    "  * Compares outlier proportions\n",
    "- IQR method (1.5 * IQR)\n",
    "  * Checks for distribution tails\n",
    "  * Validates range of values\n",
    "\n",
    "## Key Metrics for Comparison\n",
    "\n",
    "### 1. Numeric Variables\n",
    "- Trip Duration (min)\n",
    "- Distance (km)\n",
    "- Speed (km/h)\n",
    "- Temperature\n",
    "- Wind Speed\n",
    "- Relative Humidity\n",
    "\n",
    "### 2. Categorical Variables\n",
    "- User Type\n",
    "- Day of Week\n",
    "- Hour of Day\n",
    "\n",
    "### 3. Temporal Patterns\n",
    "- Hourly distribution\n",
    "- Daily patterns\n",
    "- Monthly trends\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "### 1. Statistical Similarity\n",
    "- p-values > 0.05 in statistical tests\n",
    "- Percent differences < 1% in key metrics\n",
    "- Similar outlier proportions\n",
    "\n",
    "### 2. Distribution Matching\n",
    "- Similar shapes in distributions\n",
    "- Maintained relationships between variables\n",
    "- Preserved temporal patterns\n",
    "\n",
    "### 3. Practical Significance\n",
    "- Differences should not affect analysis conclusions\n",
    "- Maintained business-relevant patterns\n",
    "- Preserved key relationships for modeling\n",
    "\n",
    "## Importance of Comprehensive Comparison\n",
    "\n",
    "### 1. Research Validity\n",
    "- Ensures sample can be used for analysis\n",
    "- Validates generalizability of findings\n",
    "- Supports research conclusions\n",
    "\n",
    "### 2. Business Impact\n",
    "- Confirms reliability for decision-making\n",
    "- Validates patterns important for operations\n",
    "- Ensures representative insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc02769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NUMERIC VARIABLES COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Trip Duration (min):\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                14.56        14.57       0.02%\n",
      "std                 13.34        13.28      -0.40%\n",
      "50%                 11.00        11.00       0.00%\n",
      "min                  1.00         1.00        N/A\n",
      "max                300.00       299.00        N/A\n",
      "KS test p-value: 0.6495\n",
      "\n",
      "Distance (km):\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                 1.97         1.97       0.02%\n",
      "std                  1.41         1.41       0.20%\n",
      "50%                  1.60         1.60      -0.11%\n",
      "min                  0.01         0.02        N/A\n",
      "max                 28.88        25.36        N/A\n",
      "KS test p-value: 0.5851\n",
      "\n",
      "Speed (km/h):\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                 9.25         9.24      -0.05%\n",
      "std                  3.38         3.38      -0.09%\n",
      "50%                  9.31         9.31      -0.04%\n",
      "min                  0.50         0.50        N/A\n",
      "max                 39.98        39.88        N/A\n",
      "KS test p-value: 0.7388\n",
      "\n",
      "Temperature:\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                14.01        14.01       0.00%\n",
      "std                  8.15         8.15       0.09%\n",
      "50%                 16.00        16.00       0.00%\n",
      "min                -14.00       -14.00        N/A\n",
      "max                 32.00        32.00        N/A\n",
      "KS test p-value: 0.9475\n",
      "\n",
      "Wind Speed:\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                16.64        16.65       0.06%\n",
      "std                  8.90         8.91       0.10%\n",
      "50%                 14.80        14.80       0.00%\n",
      "min                  0.00         0.00        N/A\n",
      "max                 64.80        64.80        N/A\n",
      "KS test p-value: 0.8409\n",
      "\n",
      "Relative Humidity:\n",
      "--------------------------------------------------\n",
      "Metric               Full      Sampled     % Diff\n",
      "--------------------------------------------------\n",
      "mean                71.63        71.64       0.01%\n",
      "std                 14.56        14.56      -0.01%\n",
      "50%                 73.00        73.00       0.00%\n",
      "min                 20.00        20.00        N/A\n",
      "max                100.00       100.00        N/A\n",
      "KS test p-value: 0.9164\n",
      "\n",
      "CATEGORICAL VARIABLES COMPARISON\n",
      "================================================================================\n",
      "\n",
      "User Type:\n",
      "--------------------------------------------------\n",
      "Category            Full %  Sampled %       Diff\n",
      "--------------------------------------------------\n",
      "Annual Member         5.74       5.74      -0.01\n",
      "Casual Member        94.26      94.26       0.01\n",
      "Chi-square test p-value: 0.8781\n",
      "\n",
      "Day of Week:\n",
      "--------------------------------------------------\n",
      "Category            Full %  Sampled %       Diff\n",
      "--------------------------------------------------\n",
      "Friday               14.68      14.70       0.02\n",
      "Monday               13.58      13.56      -0.02\n",
      "Saturday             13.95      13.99       0.04\n",
      "Sunday               12.56      12.57       0.01\n",
      "Thursday             15.04      15.05       0.01\n",
      "Tuesday              15.09      15.03      -0.07\n",
      "Wednesday            15.10      15.10       0.00\n",
      "Chi-square test p-value: 0.8862\n",
      "\n",
      "HOURLY DISTRIBUTION\n",
      "================================================================================\n",
      "Hour       Full %  Sampled %       Diff\n",
      "----------------------------------------\n",
      "0            1.39       1.40       0.01\n",
      "1            0.89       0.90       0.01\n",
      "2            0.66       0.65      -0.01\n",
      "3            0.35       0.34      -0.00\n",
      "4            0.26       0.25      -0.01\n",
      "5            0.53       0.52      -0.01\n",
      "6            1.45       1.48       0.03\n",
      "7            3.16       3.18       0.02\n",
      "8            6.60       6.61       0.01\n",
      "9            4.68       4.63      -0.05\n",
      "10           3.84       3.84       0.00\n",
      "11           4.45       4.46       0.02\n",
      "12           5.20       5.19      -0.00\n",
      "13           5.34       5.29      -0.05\n",
      "14           5.56       5.55      -0.01\n",
      "15           6.29       6.34       0.05\n",
      "16           7.98       7.94      -0.04\n",
      "17          10.58      10.56      -0.02\n",
      "18           9.07       9.12       0.06\n",
      "19           7.00       6.99      -0.01\n",
      "20           5.24       5.26       0.03\n",
      "21           4.08       4.07      -0.02\n",
      "22           3.09       3.07      -0.02\n",
      "23           2.33       2.35       0.02\n"
     ]
    }
   ],
   "source": [
    "def compare_bikeshare_stats(df, sampled_df):\n",
    "    \"\"\"\n",
    "    Compare statistical parameters between full and sampled bikeshare datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Full bikeshare dataset\n",
    "    sampled_df : pandas.DataFrame\n",
    "        Sampled dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing comparison statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define key numeric columns for detailed analysis\n",
    "    numeric_cols = [\n",
    "        'Trip Duration (min)', \n",
    "        'Distance (km)', \n",
    "        'Speed (km/h)',\n",
    "        'Temperature',\n",
    "        'Wind Speed',\n",
    "        'Relative Humidity'\n",
    "    ]\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'numeric_stats': {},\n",
    "        'categorical_distributions': {},\n",
    "        'temporal_patterns': {},\n",
    "        'statistical_tests': {}\n",
    "    }\n",
    "    \n",
    "    # 1. Numeric Statistics Comparison\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns and col in sampled_df.columns:\n",
    "            full_stats = df[col].describe()\n",
    "            sample_stats = sampled_df[col].describe()\n",
    "            \n",
    "            # Calculate percent differences\n",
    "            pct_diff = {\n",
    "                stat: ((sample_stats[stat] - full_stats[stat]) / full_stats[stat] * 100)\n",
    "                for stat in ['mean', 'std', '50%']\n",
    "                if full_stats[stat] != 0\n",
    "            }\n",
    "            \n",
    "            results['numeric_stats'][col] = {\n",
    "                'full': full_stats.to_dict(),\n",
    "                'sampled': sample_stats.to_dict(),\n",
    "                'percent_difference': pct_diff,\n",
    "                'ks_test_pvalue': stats.ks_2samp(\n",
    "                    df[col].dropna(),\n",
    "                    sampled_df[col].dropna()\n",
    "                )[1]\n",
    "            }\n",
    "    \n",
    "    # 2. Categorical Distributions\n",
    "    categorical_cols = ['User Type', 'Day of Week']\n",
    "    for col in categorical_cols:\n",
    "        full_dist = df[col].value_counts(normalize=True)\n",
    "        sample_dist = sampled_df[col].value_counts(normalize=True)\n",
    "        \n",
    "        results['categorical_distributions'][col] = {\n",
    "            'full': full_dist.to_dict(),\n",
    "            'sampled': sample_dist.to_dict(),\n",
    "            'chi_square_pvalue': stats.chi2_contingency(\n",
    "                pd.crosstab(df[col], 'Full')\n",
    "                .join(pd.crosstab(sampled_df[col], 'Sampled'))\n",
    "                .fillna(0)\n",
    "            )[1]\n",
    "        }\n",
    "    \n",
    "    # 3. Temporal Patterns\n",
    "    # Hour of day distribution\n",
    "    full_hourly = df['Hour'].value_counts(normalize=True)\n",
    "    sample_hourly = sampled_df['Hour'].value_counts(normalize=True)\n",
    "    results['temporal_patterns']['hourly'] = {\n",
    "        'full': full_hourly.to_dict(),\n",
    "        'sampled': sample_hourly.to_dict()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_comparison_results(results):\n",
    "    \"\"\"\n",
    "    Print formatted comparison results.\n",
    "    \"\"\"\n",
    "    print(\"\\nNUMERIC VARIABLES COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    for col, stats in results['numeric_stats'].items():\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\" * 50)\n",
    "        metrics = ['mean', 'std', '50%', 'min', 'max']\n",
    "        print(f\"{'Metric':<12} {'Full':>12} {'Sampled':>12} {'% Diff':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric in metrics:\n",
    "            full_val = stats['full'][metric]\n",
    "            sample_val = stats['sampled'][metric]\n",
    "            if metric in stats['percent_difference']:\n",
    "                pct_diff = stats['percent_difference'][metric]\n",
    "                print(f\"{metric:<12} {full_val:>12.2f} {sample_val:>12.2f} {pct_diff:>10.2f}%\")\n",
    "            else:\n",
    "                print(f\"{metric:<12} {full_val:>12.2f} {sample_val:>12.2f} {'N/A':>10}\")\n",
    "        print(f\"KS test p-value: {stats['ks_test_pvalue']:.4f}\")\n",
    "    \n",
    "    print(\"\\nCATEGORICAL VARIABLES COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    for col, stats in results['categorical_distributions'].items():\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Category':<15} {'Full %':>10} {'Sampled %':>10} {'Diff':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        all_categories = set(stats['full'].keys()) | set(stats['sampled'].keys())\n",
    "        for category in sorted(all_categories):\n",
    "            full_pct = stats['full'].get(category, 0) * 100\n",
    "            sample_pct = stats['sampled'].get(category, 0) * 100\n",
    "            diff = sample_pct - full_pct\n",
    "            print(f\"{str(category):<15} {full_pct:>10.2f} {sample_pct:>10.2f} {diff:>10.2f}\")\n",
    "        print(f\"Chi-square test p-value: {stats['chi_square_pvalue']:.4f}\")\n",
    "    \n",
    "    print(\"\\nHOURLY DISTRIBUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    hours = range(24)\n",
    "    print(f\"{'Hour':<6} {'Full %':>10} {'Sampled %':>10} {'Diff':>10}\")\n",
    "    print(\"-\" * 40)\n",
    "    for hour in hours:\n",
    "        full_pct = results['temporal_patterns']['hourly']['full'].get(hour, 0) * 100\n",
    "        sample_pct = results['temporal_patterns']['hourly']['sampled'].get(hour, 0) * 100\n",
    "        diff = sample_pct - full_pct\n",
    "        print(f\"{hour:<6} {full_pct:>10.2f} {sample_pct:>10.2f} {diff:>10.2f}\")\n",
    "\n",
    "# Generate and print comparison\n",
    "comparison_results = compare_bikeshare_stats(df, sampled_df)\n",
    "print_comparison_results(comparison_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ec6d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUTLIER ANALYSIS RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "Trip Duration (min):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Z-score Method (|z| > 3):\n",
      "Dataset     Outliers Count   Percentage  Max Z-score\n",
      "-------------------------------------------------------\n",
      "Full                89,963        1.69%        21.40\n",
      "Sampled              8,973        1.68%        21.42\n",
      "\n",
      "IQR Method (1.5 * IQR):\n",
      "Dataset     Outliers Count   Percentage  Lower Bound  Upper Bound\n",
      "----------------------------------------------------------------------\n",
      "Full               292,388        5.48%        -9.50        34.50\n",
      "Sampled             29,369        5.50%        -9.50        34.50\n",
      "\n",
      "Z-score Outlier Statistics:\n",
      "Metric             Full      Sampled\n",
      "-----------------------------------\n",
      "count          89963.00      8973.00\n",
      "mean              82.05        81.76\n",
      "min               55.00        55.00\n",
      "max              300.00       299.00\n",
      "\n",
      "Distance (km):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Z-score Method (|z| > 3):\n",
      "Dataset     Outliers Count   Percentage  Max Z-score\n",
      "-------------------------------------------------------\n",
      "Full               100,560        1.88%        19.08\n",
      "Sampled             10,030        1.88%        16.55\n",
      "\n",
      "IQR Method (1.5 * IQR):\n",
      "Dataset     Outliers Count   Percentage  Lower Bound  Upper Bound\n",
      "----------------------------------------------------------------------\n",
      "Full               258,486        4.84%        -1.31         4.82\n",
      "Sampled             25,890        4.85%        -1.32         4.83\n",
      "\n",
      "Z-score Outlier Statistics:\n",
      "Metric             Full      Sampled\n",
      "-----------------------------------\n",
      "count         100560.00     10030.00\n",
      "mean               7.46         7.47\n",
      "min                6.20         6.21\n",
      "max               28.88        25.36\n",
      "\n",
      "Speed (km/h):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Z-score Method (|z| > 3):\n",
      "Dataset     Outliers Count   Percentage  Max Z-score\n",
      "-------------------------------------------------------\n",
      "Full                15,526        0.29%         9.08\n",
      "Sampled              1,515        0.28%         9.06\n",
      "\n",
      "IQR Method (1.5 * IQR):\n",
      "Dataset     Outliers Count   Percentage  Lower Bound  Upper Bound\n",
      "----------------------------------------------------------------------\n",
      "Full               120,829        2.26%         1.14        17.49\n",
      "Sampled             12,199        2.29%         1.14        17.48\n",
      "\n",
      "Z-score Outlier Statistics:\n",
      "Metric             Full      Sampled\n",
      "-----------------------------------\n",
      "count          15526.00      1515.00\n",
      "mean              21.63        21.54\n",
      "min               19.40        19.39\n",
      "max               39.98        39.88\n"
     ]
    }
   ],
   "source": [
    "def analyze_outliers(df, sampled_df, columns=None):\n",
    "    \"\"\"\n",
    "    Analyze outliers in both datasets using Z-score and IQR methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Full dataset\n",
    "    sampled_df : pandas.DataFrame\n",
    "        Sampled dataset\n",
    "    columns : list, optional\n",
    "        List of numeric columns to analyze. If None, will analyze all numeric columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing outlier analysis results\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = ['Trip Duration (min)', 'Distance (km)', 'Speed (km/h)', \n",
    "                  'Temperature', 'Wind Speed', 'Relative Humidity']\n",
    "    \n",
    "    results = {\n",
    "        'zscore': {'full': {}, 'sampled': {}},\n",
    "        'iqr': {'full': {}, 'sampled': {}},\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    for col in columns:\n",
    "        # Z-score analysis\n",
    "        z_full = np.abs(stats.zscore(df[col], nan_policy='omit'))\n",
    "        z_sampled = np.abs(stats.zscore(sampled_df[col], nan_policy='omit'))\n",
    "        \n",
    "        results['zscore']['full'][col] = {\n",
    "            'outliers_count': np.sum(z_full > 3),\n",
    "            'outliers_percentage': (np.sum(z_full > 3) / len(df)) * 100,\n",
    "            'max_zscore': np.max(z_full),\n",
    "            'outlier_values': df[col][z_full > 3].describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        results['zscore']['sampled'][col] = {\n",
    "            'outliers_count': np.sum(z_sampled > 3),\n",
    "            'outliers_percentage': (np.sum(z_sampled > 3) / len(sampled_df)) * 100,\n",
    "            'max_zscore': np.max(z_sampled),\n",
    "            'outlier_values': sampled_df[col][z_sampled > 3].describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        # IQR analysis\n",
    "        Q1_full = df[col].quantile(0.25)\n",
    "        Q3_full = df[col].quantile(0.75)\n",
    "        IQR_full = Q3_full - Q1_full\n",
    "        \n",
    "        Q1_sampled = sampled_df[col].quantile(0.25)\n",
    "        Q3_sampled = sampled_df[col].quantile(0.75)\n",
    "        IQR_sampled = Q3_sampled - Q1_sampled\n",
    "        \n",
    "        lower_bound_full = Q1_full - 1.5 * IQR_full\n",
    "        upper_bound_full = Q3_full + 1.5 * IQR_full\n",
    "        \n",
    "        lower_bound_sampled = Q1_sampled - 1.5 * IQR_sampled\n",
    "        upper_bound_sampled = Q3_sampled + 1.5 * IQR_sampled\n",
    "        \n",
    "        outliers_full = df[col][(df[col] < lower_bound_full) | (df[col] > upper_bound_full)]\n",
    "        outliers_sampled = sampled_df[col][(sampled_df[col] < lower_bound_sampled) | \n",
    "                                         (sampled_df[col] > upper_bound_sampled)]\n",
    "        \n",
    "        results['iqr']['full'][col] = {\n",
    "            'Q1': Q1_full,\n",
    "            'Q3': Q3_full,\n",
    "            'IQR': IQR_full,\n",
    "            'lower_bound': lower_bound_full,\n",
    "            'upper_bound': upper_bound_full,\n",
    "            'outliers_count': len(outliers_full),\n",
    "            'outliers_percentage': (len(outliers_full) / len(df)) * 100,\n",
    "            'outlier_values': outliers_full.describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        results['iqr']['sampled'][col] = {\n",
    "            'Q1': Q1_sampled,\n",
    "            'Q3': Q3_sampled,\n",
    "            'IQR': IQR_sampled,\n",
    "            'lower_bound': lower_bound_sampled,\n",
    "            'upper_bound': upper_bound_sampled,\n",
    "            'outliers_count': len(outliers_sampled),\n",
    "            'outliers_percentage': (len(outliers_sampled) / len(sampled_df)) * 100,\n",
    "            'outlier_values': outliers_sampled.describe().to_dict()\n",
    "        }\n",
    "        \n",
    "        # Summary comparison\n",
    "        results['summary'][col] = {\n",
    "            'zscore_diff': abs(results['zscore']['full'][col]['outliers_percentage'] - \n",
    "                             results['zscore']['sampled'][col]['outliers_percentage']),\n",
    "            'iqr_diff': abs(results['iqr']['full'][col]['outliers_percentage'] - \n",
    "                          results['iqr']['sampled'][col]['outliers_percentage'])\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_outlier_analysis(results):\n",
    "    \"\"\"\n",
    "    Print formatted outlier analysis results.\n",
    "    \"\"\"\n",
    "    print(\"\\nOUTLIER ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for col in results['zscore']['full'].keys():\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Z-score results\n",
    "        print(\"\\nZ-score Method (|z| > 3):\")\n",
    "        print(f\"{'Dataset':<10} {'Outliers Count':>15} {'Percentage':>12} {'Max Z-score':>12}\")\n",
    "        print(\"-\" * 55)\n",
    "        print(f\"{'Full':<10} {results['zscore']['full'][col]['outliers_count']:>15,d} \"\n",
    "              f\"{results['zscore']['full'][col]['outliers_percentage']:>11.2f}% \"\n",
    "              f\"{results['zscore']['full'][col]['max_zscore']:>12.2f}\")\n",
    "        print(f\"{'Sampled':<10} {results['zscore']['sampled'][col]['outliers_count']:>15,d} \"\n",
    "              f\"{results['zscore']['sampled'][col]['outliers_percentage']:>11.2f}% \"\n",
    "              f\"{results['zscore']['sampled'][col]['max_zscore']:>12.2f}\")\n",
    "        \n",
    "        # IQR results\n",
    "        print(\"\\nIQR Method (1.5 * IQR):\")\n",
    "        print(f\"{'Dataset':<10} {'Outliers Count':>15} {'Percentage':>12} \"\n",
    "              f\"{'Lower Bound':>12} {'Upper Bound':>12}\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Full':<10} {results['iqr']['full'][col]['outliers_count']:>15,d} \"\n",
    "              f\"{results['iqr']['full'][col]['outliers_percentage']:>11.2f}% \"\n",
    "              f\"{results['iqr']['full'][col]['lower_bound']:>12.2f} \"\n",
    "              f\"{results['iqr']['full'][col]['upper_bound']:>12.2f}\")\n",
    "        print(f\"{'Sampled':<10} {results['iqr']['sampled'][col]['outliers_count']:>15,d} \"\n",
    "              f\"{results['iqr']['sampled'][col]['outliers_percentage']:>11.2f}% \"\n",
    "              f\"{results['iqr']['sampled'][col]['lower_bound']:>12.2f} \"\n",
    "              f\"{results['iqr']['sampled'][col]['upper_bound']:>12.2f}\")\n",
    "        \n",
    "        # Outlier value statistics\n",
    "        print(\"\\nZ-score Outlier Statistics:\")\n",
    "        stats_to_show = ['count', 'mean', 'min', 'max']\n",
    "        print(f\"{'Metric':<10} {'Full':>12} {'Sampled':>12}\")\n",
    "        print(\"-\" * 35)\n",
    "        for stat in stats_to_show:\n",
    "            full_val = results['zscore']['full'][col]['outlier_values'][stat]\n",
    "            samp_val = results['zscore']['sampled'][col]['outlier_values'][stat]\n",
    "            print(f\"{stat:<10} {full_val:>12.2f} {samp_val:>12.2f}\")\n",
    "\n",
    "# Example usage\n",
    "columns_to_analyze = ['Trip Duration (min)', 'Distance (km)', 'Speed (km/h)']\n",
    "outlier_results = analyze_outliers(df, sampled_df, columns=columns_to_analyze)\n",
    "print_outlier_analysis(outlier_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47801e9",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Toronto Bikeshare Data Sampling\n",
    "\n",
    "## 1. Overview of Statistical Comparison\n",
    "\n",
    "### 1.1 Numeric Variables Analysis\n",
    "The comparison of numeric variables shows exceptional consistency between the full and sampled datasets:\n",
    "\n",
    "#### Trip Duration\n",
    "- Mean difference: 0.02% (14.56 vs 14.57 minutes)\n",
    "- Standard deviation difference: -0.40% (13.34 vs 13.28)\n",
    "- KS test p-value: 0.6495 (indicates similar distributions)\n",
    "- Range maintained: 1-300 minutes (full) vs 1-299 minutes (sampled)\n",
    "\n",
    "#### Distance\n",
    "- Mean difference: 0.02% (1.97 km in both)\n",
    "- Standard deviation difference: 0.20%\n",
    "- KS test p-value: 0.5851\n",
    "- Minor difference in maximum values: 28.88 km vs 25.36 km\n",
    "\n",
    "#### Speed\n",
    "- Mean difference: -0.05% (9.25 vs 9.24 km/h)\n",
    "- Standard deviation difference: -0.09%\n",
    "- KS test p-value: 0.7388\n",
    "- Consistent range: 0.50-39.98 km/h vs 0.50-39.88 km/h\n",
    "\n",
    "### 1.2 Categorical Variables\n",
    "The sampling maintained nearly identical categorical distributions:\n",
    "\n",
    "#### User Type Distribution\n",
    "- Annual Members: 5.74% in both datasets (diff: -0.01)\n",
    "- Casual Members: 94.26% in both datasets (diff: 0.01)\n",
    "- Chi-square p-value: 0.8781 (strong similarity)\n",
    "\n",
    "#### Day of Week Distribution\n",
    "- Maximum difference: -0.07% (Tuesday)\n",
    "- Most days show differences < 0.05%\n",
    "- Chi-square p-value: 0.8862\n",
    "- Maintained weekly patterns\n",
    "\n",
    "### 1.3 Hourly Distribution\n",
    "Temporal patterns were preserved with high accuracy:\n",
    "\n",
    "- Peak hour (17:00): 10.58% vs 10.56% (diff: -0.02%)\n",
    "- Morning peak (08:00): 6.60% vs 6.61% (diff: 0.01%)\n",
    "- Maximum difference: 0.06% at 18:00\n",
    "- Maintained 24-hour usage pattern\n",
    "\n",
    "## 2. Outlier Analysis Results\n",
    "\n",
    "### 2.1 Trip Duration Outliers\n",
    "\n",
    "#### Z-score Method (|z| > 3)\n",
    "- Full dataset: 1.69% outliers (89,963 trips)\n",
    "- Sampled dataset: 1.68% outliers (8,973 trips)\n",
    "- Very consistent outlier percentage\n",
    "- Similar max z-scores: 21.40 vs 21.42\n",
    "- Outlier characteristics:\n",
    "  * Mean duration: 82.05 vs 81.76 minutes\n",
    "  * Range: 55-300 vs 55-299 minutes\n",
    "\n",
    "#### IQR Method\n",
    "- Full dataset: 5.48% outliers (292,388 trips)\n",
    "- Sampled dataset: 5.50% outliers (29,369 trips)\n",
    "- Identical boundaries: [-9.50, 34.50] minutes\n",
    "- Higher detection rate than z-score method\n",
    "\n",
    "### 2.2 Distance Outliers\n",
    "\n",
    "#### Z-score Method (|z| > 3)\n",
    "- Full dataset: 1.88% outliers (100,560 trips)\n",
    "- Sampled dataset: 1.88% outliers (10,030 trips)\n",
    "- Max z-scores: 19.08 vs 16.55\n",
    "- Outlier characteristics:\n",
    "  * Mean distance: 7.46 vs 7.47 km\n",
    "  * Range: 6.20-28.88 vs 6.21-25.36 km\n",
    "\n",
    "#### IQR Method\n",
    "- Full dataset: 4.84% outliers (258,486 trips)\n",
    "- Sampled dataset: 4.85% outliers (25,890 trips)\n",
    "- Nearly identical boundaries: [-1.31, 4.82] vs [-1.32, 4.83] km\n",
    "\n",
    "### 2.3 Speed Outliers\n",
    "\n",
    "#### Z-score Method (|z| > 3)\n",
    "- Full dataset: 0.29% outliers (15,526 trips)\n",
    "- Sampled dataset: 0.28% outliers (1,515 trips)\n",
    "- Similar max z-scores: 9.08 vs 9.06\n",
    "- Outlier characteristics:\n",
    "  * Mean speed: 21.63 vs 21.54 km/h\n",
    "  * Range: 19.40-39.98 vs 19.39-39.88 km/h\n",
    "\n",
    "#### IQR Method\n",
    "- Full dataset: 2.26% outliers (120,829 trips)\n",
    "- Sampled dataset: 2.29% outliers (12,199 trips)\n",
    "- Consistent boundaries: [1.14, 17.49] vs [1.14, 17.48] km/h\n",
    "\n",
    "## 3. Key Findings\n",
    "\n",
    "### 3.1 Sampling Quality\n",
    "1. All statistical tests show strong similarity (p-values > 0.5)\n",
    "2. Percentage differences consistently < 0.5%\n",
    "3. Maintained distributions across all variable types\n",
    "4. Preserved temporal patterns and user type distributions\n",
    "\n",
    "### 3.2 Outlier Representation\n",
    "1. Consistent outlier percentages across both methods\n",
    "2. Maintained extreme value characteristics\n",
    "3. Similar outlier boundaries and statistics\n",
    "4. Proper representation of unusual trips\n",
    "\n",
    "### 3.3 Practical Implications\n",
    "1. Sample is highly representative of full dataset\n",
    "2. Suitable for detailed analysis and modeling\n",
    "3. Maintains data quality and characteristics\n",
    "4. Captures both normal and unusual patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f741f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('Toronto Bikeshare Sampled dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
