{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee53c4e7",
   "metadata": {},
   "source": [
    "Method 1: Use WEB SCRAPER from Chrome Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752434f0",
   "metadata": {},
   "source": [
    "Method 2: General Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9e7d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BARNATO 2024 Sponsor Pass</td>\n",
       "      <td>Jan01</td>\n",
       "      <td>12/31/24</td>\n",
       "      <td>BARNATO 2024 Sponsor Pass, Omaha, NE, Barnato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BARNATO 2024 Sponsor Pass</td>\n",
       "      <td>Jan01</td>\n",
       "      <td>12/31/24</td>\n",
       "      <td>BARNATO 2024 Sponsor Pass, Omaha, NE, Barnato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket for you and a +1 to ALL 2024 shows at t...</td>\n",
       "      <td>Jan03</td>\n",
       "      <td>12/31/24</td>\n",
       "      <td>Ticket for you and a +1 to ALL 2024 shows at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPS GOLDEN TICKETS</td>\n",
       "      <td>Mar09</td>\n",
       "      <td>10/1/25</td>\n",
       "      <td>CPS GOLDEN TICKETS, Eugene, OR, The Big Dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VIP Passes to The Liberty</td>\n",
       "      <td>Jun12</td>\n",
       "      <td>6/30/25</td>\n",
       "      <td>VIP Passes to The Liberty, Roswell, NM, The Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Tuesday...</td>\n",
       "      <td>Sep17</td>\n",
       "      <td>6/24/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Tuesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Wednesd...</td>\n",
       "      <td>Sep18</td>\n",
       "      <td>6/25/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Wednesd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Warren Civic Music Series 2024-2025</td>\n",
       "      <td>Sep18</td>\n",
       "      <td>5/1/25</td>\n",
       "      <td>Warren Civic Music Series 2024-2025, Warren, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Thursda...</td>\n",
       "      <td>Sep19</td>\n",
       "      <td>6/26/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Friday ...</td>\n",
       "      <td>Sep20</td>\n",
       "      <td>6/27/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Friday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Saturda...</td>\n",
       "      <td>Sep21</td>\n",
       "      <td>6/28/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Saturda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Saturda...</td>\n",
       "      <td>Sep21</td>\n",
       "      <td>6/28/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Saturda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Morgan State Bears Football 2024 Season Tickets</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>Morgan State Bears Football 2024 Season Ticket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fall EDM Pass 2024 feat. Peekaboo, Midnight Ty...</td>\n",
       "      <td>Sep21</td>\n",
       "      <td>12/20/24</td>\n",
       "      <td>Fall EDM Pass 2024 feat. Peekaboo, Midnight Ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Sunday ...</td>\n",
       "      <td>Sep22</td>\n",
       "      <td>6/29/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-2025 First Bank Broadway Season - Sunday ...</td>\n",
       "      <td>Sep22</td>\n",
       "      <td>6/29/25</td>\n",
       "      <td>2024-2025 First Bank Broadway Season - Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Trumbull Town Hall 2024-2025 Series</td>\n",
       "      <td>Sep25</td>\n",
       "      <td>4/30/25</td>\n",
       "      <td>Trumbull Town Hall 2024-2025 Series, Warren, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Disney Tim Burton's The Nightmare Before Chris...</td>\n",
       "      <td>Sep26</td>\n",
       "      <td>11/30/24</td>\n",
       "      <td>Disney Tim Burton's The Nightmare Before Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Broadway 2024-25 Season</td>\n",
       "      <td>Oct10</td>\n",
       "      <td>3/13/25</td>\n",
       "      <td>Broadway 2024-25 Season, Davenport, IA, Adler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Las Vegas Travel Packages - Create a Ticket + ...</td>\n",
       "      <td>Oct17</td>\n",
       "      <td>12/30/24</td>\n",
       "      <td>Las Vegas Travel Packages - Create a Ticket + ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Event Name Start Date  End Date  \\\n",
       "0                           BARNATO 2024 Sponsor Pass      Jan01  12/31/24   \n",
       "1                           BARNATO 2024 Sponsor Pass      Jan01  12/31/24   \n",
       "2                                                 N/A        N/A       N/A   \n",
       "3   Ticket for you and a +1 to ALL 2024 shows at t...      Jan03  12/31/24   \n",
       "4                                  CPS GOLDEN TICKETS      Mar09   10/1/25   \n",
       "5                           VIP Passes to The Liberty      Jun12   6/30/25   \n",
       "6   2024-2025 First Bank Broadway Season - Tuesday...      Sep17   6/24/25   \n",
       "7   2024-2025 First Bank Broadway Season - Wednesd...      Sep18   6/25/25   \n",
       "8                 Warren Civic Music Series 2024-2025      Sep18    5/1/25   \n",
       "9   2024-2025 First Bank Broadway Season - Thursda...      Sep19   6/26/25   \n",
       "10  2024-2025 First Bank Broadway Season - Friday ...      Sep20   6/27/25   \n",
       "11  2024-2025 First Bank Broadway Season - Saturda...      Sep21   6/28/25   \n",
       "12  2024-2025 First Bank Broadway Season - Saturda...      Sep21   6/28/25   \n",
       "13    Morgan State Bears Football 2024 Season Tickets                  N/A   \n",
       "14  Fall EDM Pass 2024 feat. Peekaboo, Midnight Ty...      Sep21  12/20/24   \n",
       "15  2024-2025 First Bank Broadway Season - Sunday ...      Sep22   6/29/25   \n",
       "16  2024-2025 First Bank Broadway Season - Sunday ...      Sep22   6/29/25   \n",
       "17                Trumbull Town Hall 2024-2025 Series      Sep25   4/30/25   \n",
       "18  Disney Tim Burton's The Nightmare Before Chris...      Sep26  11/30/24   \n",
       "19                            Broadway 2024-25 Season      Oct10   3/13/25   \n",
       "20  Las Vegas Travel Packages - Create a Ticket + ...      Oct17  12/30/24   \n",
       "\n",
       "                                             Location  \n",
       "0       BARNATO 2024 Sponsor Pass, Omaha, NE, Barnato  \n",
       "1       BARNATO 2024 Sponsor Pass, Omaha, NE, Barnato  \n",
       "2                                                 N/A  \n",
       "3   Ticket for you and a +1 to ALL 2024 shows at t...  \n",
       "4       CPS GOLDEN TICKETS, Eugene, OR, The Big Dirty  \n",
       "5   VIP Passes to The Liberty, Roswell, NM, The Li...  \n",
       "6   2024-2025 First Bank Broadway Season - Tuesday...  \n",
       "7   2024-2025 First Bank Broadway Season - Wednesd...  \n",
       "8   Warren Civic Music Series 2024-2025, Warren, O...  \n",
       "9   2024-2025 First Bank Broadway Season - Thursda...  \n",
       "10  2024-2025 First Bank Broadway Season - Friday ...  \n",
       "11  2024-2025 First Bank Broadway Season - Saturda...  \n",
       "12  2024-2025 First Bank Broadway Season - Saturda...  \n",
       "13  Morgan State Bears Football 2024 Season Ticket...  \n",
       "14  Fall EDM Pass 2024 feat. Peekaboo, Midnight Ty...  \n",
       "15  2024-2025 First Bank Broadway Season - Sunday ...  \n",
       "16  2024-2025 First Bank Broadway Season - Sunday ...  \n",
       "17  Trumbull Town Hall 2024-2025 Series, Warren, O...  \n",
       "18  Disney Tim Burton's The Nightmare Before Chris...  \n",
       "19  Broadway 2024-25 Season, Davenport, IA, Adler ...  \n",
       "20  Las Vegas Travel Packages - Create a Ticket + ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first page\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Event list URL and headers\n",
    "url = \"https://www.ticketmaster.com/search?q=&sort=date&startDate=2024-10-24&endDate=2024-11-30\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Request page content and parse with BeautifulSoup\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Lists for storing data\n",
    "events = []\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "locations = []\n",
    "\n",
    "# Find event elements in the page\n",
    "event_elements = soup.find_all('li', class_='sc-1nyzlro-1')  # Update this based on actual event container class\n",
    "\n",
    "# Extract details from each event element\n",
    "for event in event_elements:\n",
    "    # Event name\n",
    "    event_name = event.find('span', class_='sc-fyofxi-5').text if event.find('span', class_='sc-fyofxi-5') else \"N/A\"\n",
    "    \n",
    "    # Event start date\n",
    "    start_date = event.find('div', class_='sc-1evs0j0-0').text if event.find('div', class_='sc-1evs0j0-0') else \"N/A\"\n",
    "    \n",
    "    # Event end date\n",
    "    end_date_element = event.find('span', class_='sc-1idcr5x-0 bihyed')\n",
    "    if end_date_element:\n",
    "        # Find the inner span that contains the detailed date\n",
    "        detailed_span = end_date_element.find('span', class_='VisuallyHidden-sc-8buqks-0')\n",
    "        if detailed_span:\n",
    "            # Extract the date without the \"Until\" text\n",
    "            end_date = detailed_span.find('span').text.strip() if detailed_span else \"N/A\"\n",
    "        else:\n",
    "            # Fallback to extracting the visible date part, if any\n",
    "            visible_end_date = end_date_element.find('span', aria_hidden=True)\n",
    "            end_date = visible_end_date.text.strip() if visible_end_date else \"N/A\"\n",
    "    else:\n",
    "        end_date = \"N/A\"\n",
    "\n",
    "    \n",
    "    # Location details\n",
    "    location_elements = event.find_all('span', class_='sc-fyofxi-5')\n",
    "    location = \", \".join([loc.text for loc in location_elements if loc.text]) if location_elements else \"N/A\"\n",
    "    \n",
    "    # Append to lists\n",
    "    events.append(event_name)\n",
    "    start_dates.append(start_date)\n",
    "    end_dates.append(end_date)\n",
    "    locations.append(location)\n",
    "\n",
    "    # Pause to avoid rapid requests\n",
    "    time.sleep(1)\n",
    "\n",
    "# Create DataFrame and drop rows where all columns are N/A\n",
    "df1 = pd.DataFrame({\n",
    "    'Event Name': events,\n",
    "    'Start Date': start_dates,\n",
    "    'End Date': end_dates,\n",
    "    'Location': locations\n",
    "})\n",
    "\n",
    "# Drop rows where all columns are NA\n",
    "df1.dropna(how='all', inplace=True)\n",
    "\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requrie all pages\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Event list URL and headers\n",
    "base_url = \"https://www.ticketmaster.com/search\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Lists for storing data\n",
    "events = []\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "locations = []\n",
    "\n",
    "# Pagination variables\n",
    "page = 1\n",
    "while True:\n",
    "    # Construct URL with page parameter\n",
    "    url = f\"{base_url}?q=&sort=date&startDate=2024-10-24&endDate=2024-10-30&page={page}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find event elements on the current page\n",
    "    event_elements = soup.find_all('li', class_='sc-1nyzlro-1')\n",
    "    \n",
    "    # If no events are found, break the loop\n",
    "    if not event_elements:\n",
    "        break\n",
    "    \n",
    "    # Extract details from each event element\n",
    "    for event in event_elements:\n",
    "        # Event name\n",
    "        event_name = event.find('span', class_='sc-fyofxi-5').text if event.find('span', class_='sc-fyofxi-5') else \"N/A\"\n",
    "        \n",
    "        # Event start and end dates\n",
    "        start_date = event.find('div', class_='sc-1evs0j0-0').text if event.find('div', class_='sc-1evs0j0-0') else \"N/A\"\n",
    "   \n",
    "        end_date_element = event.find('span', class_='sc-1idcr5x-0 bihyed')\n",
    "        if end_date_element:\n",
    "            # Find the inner span that contains the detailed date\n",
    "            detailed_span = end_date_element.find('span', class_='VisuallyHidden-sc-8buqks-0')\n",
    "            if detailed_span:\n",
    "                # Extract the date without the \"Until\" text\n",
    "                end_date = detailed_span.find('span').text.strip() if detailed_span else \"N/A\"\n",
    "            else:\n",
    "                # Fallback to extracting the visible date part, if any\n",
    "                visible_end_date = end_date_element.find('span', aria_hidden=True)\n",
    "                end_date = visible_end_date.text.strip() if visible_end_date else \"N/A\"\n",
    "        else:\n",
    "            end_date = \"N/A\"\n",
    "        \n",
    "        # Location details\n",
    "        location_elements = event.find_all('span', class_='sc-fyofxi-5')\n",
    "        location = \", \".join([loc.text for loc in location_elements]) if location_elements else \"N/A\"\n",
    "        \n",
    "        # Append to lists\n",
    "        events.append(event_name)\n",
    "        start_dates.append(start_date)\n",
    "        end_dates.append(end_date)\n",
    "        locations.append(location)\n",
    "\n",
    "    # Pause to avoid rapid requests\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Go to the next page\n",
    "    page += 1\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df2 = pd.DataFrame({\n",
    "    'Event Name': events,\n",
    "    'Start Date': start_dates,\n",
    "    'End Date': end_dates,\n",
    "    'Location': locations\n",
    "})\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d32a25",
   "metadata": {},
   "source": [
    "Method 3: Use SCRPAFLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first page\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List\n",
    "import urllib\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger as log\n",
    "from scrapfly import ScrapeApiResponse, ScrapeConfig, ScrapflyClient, ScrapflyScrapeError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Accessing the API key from environment variables\n",
    "scrapfly_api_key = os.getenv('SCRAPFLY_API_KEY') or \"scp-live-27c7deed8b60458a95244a22f389179d\"\n",
    "\n",
    "# Using the API key to configure ScrapflyClient\n",
    "SCRAPFLY = ScrapflyClient(key=scrapfly_api_key, max_concurrency=5)\n",
    "BASE_CONFIG = {\n",
    "    \"asp\": True,\n",
    "    \"country\": \"us\",\n",
    "}\n",
    "\n",
    "def parse_search_page(result):\n",
    "    \"\"\"Extract event data from the Ticketmaster page HTML.\"\"\"\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    event_elements = soup.find_all('li', class_='sc-1nyzlro-1')\n",
    "    events = []\n",
    "\n",
    "    for event in event_elements:\n",
    "        event_name = event.find('span', class_='sc-fyofxi-5').text if event.find('span', class_='sc-fyofxi-5') else \"N/A\"\n",
    "        start_date = event.find('div', class_='sc-1evs0j0-0').text if event.find('div', class_='sc-1evs0j0-0') else \"N/A\"\n",
    "        end_date_element = event.find('span', class_='sc-1idcr5x-0 bihyed')\n",
    "        if end_date_element:\n",
    "            # Find the inner span that contains the detailed date\n",
    "            detailed_span = end_date_element.find('span', class_='VisuallyHidden-sc-8buqks-0')\n",
    "            if detailed_span:\n",
    "                # Extract the date without the \"Until\" text\n",
    "                end_date = detailed_span.find('span').text.strip() if detailed_span else \"N/A\"\n",
    "            else:\n",
    "                # Fallback to extracting the visible date part, if any\n",
    "                visible_end_date = end_date_element.find('span', aria_hidden=True)\n",
    "                end_date = visible_end_date.text.strip() if visible_end_date else \"N/A\"\n",
    "        else:\n",
    "            end_date = \"N/A\"\n",
    "        location_elements = event.find_all('span', class_='sc-fyofxi-5')\n",
    "        location = ', '.join([loc.text for loc in location_elements])\n",
    "\n",
    "        events.append({\n",
    "            \"Event Name\": event_name,\n",
    "            \"Start Date\": start_date,\n",
    "            \"End Date\": end_date,\n",
    "            \"Location\": location\n",
    "        })\n",
    "\n",
    "    if not events:\n",
    "        log.warning(\"No event data found on page.\")\n",
    "\n",
    "    return events\n",
    "\n",
    "# Add page number to URL\n",
    "def _add_url_parameter(url, **kwargs):\n",
    "    \"\"\"Add or replace GET parameters in a URL.\"\"\"\n",
    "    url_parts = list(urllib.parse.urlparse(url))\n",
    "    query = dict(urllib.parse.parse_qsl(url_parts[4]))\n",
    "    query.update(kwargs)\n",
    "    url_parts[4] = urllib.parse.urlencode(query)\n",
    "    return urllib.parse.urlunparse(url_parts)\n",
    "\n",
    "async def scrape_search(url: str, max_results: int = 100) -> List[Dict]:\n",
    "    log.info(f\"Scraping Ticketmaster events: {url}\")\n",
    "    result_first_page = await SCRAPFLY.async_scrape(ScrapeConfig(url, **BASE_CONFIG))\n",
    "\n",
    "    # Parse the first page\n",
    "    events = parse_search_page(result_first_page)\n",
    "    \n",
    "    return events\n",
    "\n",
    "async def run():\n",
    "    BASE_CONFIG[\"cache\"] = False\n",
    "    url = \"https://www.ticketmaster.com/search?sort=date&startDate=2024-11-06&endDate=2024-11-06\"\n",
    "    result_search = await scrape_search(url)\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(result_search)\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all pages and then scrape\n",
    "\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def parse_event_page(result):\n",
    "    \"\"\"Parse event data from Ticketmaster page HTML.\"\"\"\n",
    "    # Assuming event data can be found by a similar structure as provided.\n",
    "    events = re.findall(r'<div class=\"sc-fyofxi-0 MDVIb\">(.*?)<a href=\"(.*?)\" data-testid=\"event-list-link\"', result, re.DOTALL)\n",
    "\n",
    "    parsed_events = []\n",
    "    for event in events:\n",
    "        title_match = re.search(r'jXhNIe.*?>(.*?)</span>', event[0])\n",
    "        location_match = re.search(r'jWLmQR.*?>(.*?)</span>', event[0])\n",
    "        date_match = re.search(r'jifFsK.*?>(.*?)</span>', event[0])\n",
    "        \n",
    "        title = title_match.group(1) if title_match else \"N/A\"\n",
    "        location = location_match.group(1) if location_match else \"N/A\"\n",
    "        date = date_match.group(1) if date_match else \"N/A\"\n",
    "        url = event[1]\n",
    "\n",
    "        parsed_events.append({\n",
    "            \"title\": title,\n",
    "            \"location\": location,\n",
    "            \"date\": date,\n",
    "            \"url\": f\"https://www.ticketmaster.com{url}\"\n",
    "        })\n",
    "\n",
    "    return parsed_events\n",
    "\n",
    "async def load_all_events(url: str, max_results: int = 1000) -> List[Dict]:\n",
    "    log.info(f\"scraping events: {url}\")\n",
    "    \n",
    "    # Scrape the first page\n",
    "    result_first_page = await SCRAPFLY.async_scrape(ScrapeConfig(url, **BASE_CONFIG))\n",
    "    \n",
    "    # Access content and parse the event data\n",
    "    results = parse_event_page(result_first_page.content)\n",
    "    \n",
    "    # Keep clicking the \"More Events\" button to load all events\n",
    "    loaded_events = len(results)\n",
    "    page_num = 1\n",
    "\n",
    "    while loaded_events < max_results:\n",
    "        # Add an offset for each \"More Events\" page load\n",
    "        next_url = _add_url_parameter(url, page=str(page_num))\n",
    "        next_page = await SCRAPFLY.async_scrape(ScrapeConfig(next_url, **BASE_CONFIG))\n",
    "        \n",
    "        if isinstance(next_page, ScrapflyScrapeError):\n",
    "            log.error(f\"Failed to load page {page_num}: {next_page.message}\")\n",
    "            break\n",
    "\n",
    "        # Access content and parse the event data\n",
    "        new_events = parse_event_page(next_page.content)\n",
    "        results.extend(new_events)\n",
    "\n",
    "        # Update loaded count and page number\n",
    "        loaded_events += len(new_events)\n",
    "        page_num += 1\n",
    "\n",
    "        log.info(f\"Loaded {loaded_events} events so far\")\n",
    "\n",
    "        # Break if \"More Events\" button is gone or max results reached\n",
    "        if not new_events or loaded_events >= max_results:\n",
    "            break\n",
    "\n",
    "        # Pause briefly to mimic human-like interaction\n",
    "        time.sleep(1)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "async def run_scraping():\n",
    "    BASE_CONFIG[\"cache\"] = False\n",
    "    print(\"Starting Ticketmaster scrape...\")\n",
    "\n",
    "    # URL for events on November 8, 2024\n",
    "    base_url = \"https://www.ticketmaster.com/search?sort=date&startDate=2024-11-08&endDate=2024-11-08\"\n",
    "\n",
    "    # Load all events\n",
    "    scraped_events = await load_all_events(base_url)\n",
    "\n",
    "    # Save to a DataFrame and CSV\n",
    "    df = pd.DataFrame(scraped_events)\n",
    "    print(df)\n",
    "\n",
    "    print(\"Scraping complete.\")\n",
    "\n",
    "# Run the scraping function\n",
    "await run_scraping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adabba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV if needed\n",
    "\n",
    "df.to_csv('ticketmaster_events.csv', index=False)\n",
    "print(\"Data saved to 'ticketmaster_events.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2995e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738aa10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cd101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
